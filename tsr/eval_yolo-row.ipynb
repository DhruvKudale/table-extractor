{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3cc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "import pathlib\n",
    "import glob\n",
    "import tqdm\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa9b3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_preds(img, docseg_model, thresh, shrink_ht = 1, shrink_wt = 1):\n",
    "    image = cv2.imread(img, 0)\n",
    "    orig_image = image.copy()\n",
    "    # BGR to RGB\n",
    "    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    # Resize the image\n",
    "    height, width, _ = image.shape\n",
    "    dets = []\n",
    "    results = docseg_model(image, save=True, show_labels=False, show_conf=False, show_boxes=True, conf = conf_thresh)\n",
    "    #results[0].save(filename = f'/home/dhruv/Projects/TD-Results/YOLO/{dataset}/{mode}/' + img.split('/')[-1])\n",
    "    for entry in results:\n",
    "        bboxes = entry.boxes.xyxy.numpy()\n",
    "        classes = entry.boxes.cls.numpy()\n",
    "        conf = entry.boxes.conf.numpy()\n",
    "        for i in range(len(bboxes)):\n",
    "            box = bboxes[i]\n",
    "            if conf[i] > thresh:\n",
    "                dets.append([0, box[1], width, box[3]])\n",
    "    return dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c8f2b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO model\n",
    "docseg_model = YOLO('model/yolo-row-300.pt')\n",
    "docseg_model.overrides['iou'] = 0.2  # NMS IoU threshold\n",
    "conf_thresh = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2483dea",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "460fa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c1eea500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(img_file, bboxes, color = (255, 0, 255), thickness= 2):\n",
    "    image = cv2.imread(img_file)\n",
    "    for b in bboxes:\n",
    "        start_point = (int(b[0]), int(b[1]))\n",
    "        end_point = (int(b[2]), int(b[3]))\n",
    "        image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "653f12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_dets(height, width, dets, thresh):\n",
    "    ys = []\n",
    "    # First one y is 0\n",
    "    dets[0][1] = 0\n",
    "    # Last one y is height\n",
    "    dets[-1][1] = height \n",
    "    for d in dets:\n",
    "        ys.append(int(d[1]))\n",
    "        ys.append(int(d[3]))\n",
    "    ys.sort()\n",
    "    final_ys = []\n",
    "    for i in range(len(ys[:-1])):\n",
    "        if ys[i + 1] - ys[i] > thresh:\n",
    "            final_ys.append(ys[i])\n",
    "    final_ys.append(height)\n",
    "    print(final_ys)\n",
    "    res = []\n",
    "    for i in range(len(final_ys[:-1])):\n",
    "        res.append([0, final_ys[i], width, final_ys[i + 1]])\n",
    "    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d3ee450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Image Function\n",
    "def get_yolo_rows(img_file):\n",
    "    dets = get_yolo_preds(img_file, docseg_model, conf_thresh)\n",
    "    image = cv2.imread(img_file)\n",
    "    ht, wt, _ = image.shape\n",
    "    processed_dets = post_process_dets(ht, wt, dets, int(ht * 0.05))\n",
    "    return processed_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e9e7cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# List of sample images to process\n",
    "img_path = '*.png'\n",
    "img_list = glob.glob(img_path)\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ebeb6e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x640 10 table rows, 34.4ms\n",
      "Speed: 2.2ms preprocess, 34.4ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[2, 66, 110, 158, 233, 275, 317, 366, 440, 525, 628]\n",
      "[[0, 2, 1509, 66], [0, 66, 1509, 110], [0, 110, 1509, 158], [0, 158, 1509, 233], [0, 233, 1509, 275], [0, 275, 1509, 317], [0, 317, 1509, 366], [0, 366, 1509, 440], [0, 440, 1509, 525], [0, 525, 1509, 628]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 2, 1509, 66],\n",
       " [0, 66, 1509, 110],\n",
       " [0, 110, 1509, 158],\n",
       " [0, 158, 1509, 233],\n",
       " [0, 233, 1509, 275],\n",
       " [0, 275, 1509, 317],\n",
       " [0, 317, 1509, 366],\n",
       " [0, 366, 1509, 440],\n",
       " [0, 440, 1509, 525],\n",
       " [0, 525, 1509, 628]]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_yolo_rows(img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e761c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x640 10 table rows, 33.2ms\n",
      "Speed: 2.5ms preprocess, 33.2ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[2, 66, 110, 158, 233, 275, 317, 366, 440, 525, 628]\n",
      "[[0, 2, 1509, 66], [0, 66, 1509, 110], [0, 110, 1509, 158], [0, 158, 1509, 233], [0, 233, 1509, 275], [0, 275, 1509, 317], [0, 317, 1509, 366], [0, 366, 1509, 440], [0, 440, 1509, 525], [0, 525, 1509, 628]]\n",
      "\n",
      "0: 288x640 12 table rows, 29.8ms\n",
      "Speed: 2.3ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[2, 61, 110, 156, 232, 273, 316, 363, 440, 525, 574, 635]\n",
      "[[0, 2, 1533, 61], [0, 61, 1533, 110], [0, 110, 1533, 156], [0, 156, 1533, 232], [0, 232, 1533, 273], [0, 273, 1533, 316], [0, 316, 1533, 363], [0, 363, 1533, 440], [0, 440, 1533, 525], [0, 525, 1533, 574], [0, 574, 1533, 635]]\n",
      "\n",
      "0: 288x640 10 table rows, 31.2ms\n",
      "Speed: 4.2ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[6, 53, 91, 129, 194, 228, 265, 332, 396, 462, 557]\n",
      "[[0, 6, 1275, 53], [0, 53, 1275, 91], [0, 91, 1275, 129], [0, 129, 1275, 194], [0, 194, 1275, 228], [0, 228, 1275, 265], [0, 265, 1275, 332], [0, 332, 1275, 396], [0, 396, 1275, 462], [0, 462, 1275, 557]]\n",
      "\n",
      "0: 288x640 11 table rows, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[2, 66, 110, 158, 231, 274, 317, 365, 439, 525, 573, 630]\n",
      "[[0, 2, 1531, 66], [0, 66, 1531, 110], [0, 110, 1531, 158], [0, 158, 1531, 231], [0, 231, 1531, 274], [0, 274, 1531, 317], [0, 317, 1531, 365], [0, 365, 1531, 439], [0, 439, 1531, 525], [0, 525, 1531, 573], [0, 573, 1531, 630]]\n",
      "\n",
      "0: 288x640 10 table rows, 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[4, 64, 110, 157, 234, 274, 318, 400, 475, 554, 668]\n",
      "[[0, 4, 1533, 64], [0, 64, 1533, 110], [0, 110, 1533, 157], [0, 157, 1533, 234], [0, 234, 1533, 274], [0, 274, 1533, 318], [0, 318, 1533, 400], [0, 400, 1533, 475], [0, 475, 1533, 554], [0, 554, 1533, 668]]\n",
      "\n",
      "0: 320x640 11 table rows, 30.7ms\n",
      "Speed: 2.2ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[32, 69, 114, 191, 237, 311, 354, 438, 513, 602, 646, 701]\n",
      "[[0, 32, 1553, 69], [0, 69, 1553, 114], [0, 114, 1553, 191], [0, 191, 1553, 237], [0, 237, 1553, 311], [0, 311, 1553, 354], [0, 354, 1553, 438], [0, 438, 1553, 513], [0, 513, 1553, 602], [0, 602, 1553, 646], [0, 646, 1553, 701]]\n",
      "\n",
      "0: 256x640 8 table rows, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[5, 59, 105, 151, 263, 312, 360, 435, 520, 618]\n",
      "[[0, 5, 1565, 59], [0, 59, 1565, 105], [0, 105, 1565, 151], [0, 151, 1565, 263], [0, 263, 1565, 312], [0, 312, 1565, 360], [0, 360, 1565, 435], [0, 435, 1565, 520], [0, 520, 1565, 618]]\n",
      "\n",
      "0: 288x640 12 table rows, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[18, 62, 99, 137, 202, 234, 270, 339, 401, 524, 565]\n",
      "[[0, 18, 1299, 62], [0, 62, 1299, 99], [0, 99, 1299, 137], [0, 137, 1299, 202], [0, 202, 1299, 234], [0, 234, 1299, 270], [0, 270, 1299, 339], [0, 339, 1299, 401], [0, 401, 1299, 524], [0, 524, 1299, 565]]\n",
      "\n",
      "0: 288x640 10 table rows, 34.3ms\n",
      "Speed: 5.6ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[1, 52, 88, 128, 192, 226, 264, 329, 389, 465, 554]\n",
      "[[0, 1, 1295, 52], [0, 52, 1295, 88], [0, 88, 1295, 128], [0, 128, 1295, 192], [0, 192, 1295, 226], [0, 226, 1295, 264], [0, 264, 1295, 329], [0, 329, 1295, 389], [0, 389, 1295, 465], [0, 465, 1295, 554]]\n",
      "\n",
      "0: 288x640 10 table rows, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[3, 66, 110, 157, 199, 235, 274, 317, 401, 477, 556, 666]\n",
      "[[0, 3, 1558, 66], [0, 66, 1558, 110], [0, 110, 1558, 157], [0, 157, 1558, 199], [0, 199, 1558, 235], [0, 235, 1558, 274], [0, 274, 1558, 317], [0, 317, 1558, 401], [0, 401, 1558, 477], [0, 477, 1558, 556], [0, 556, 1558, 666]]\n",
      "\n",
      "0: 288x640 12 table rows, 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "[0, 63, 109, 153, 231, 273, 315, 364, 440, 525, 576, 631]\n",
      "[[0, 0, 1525, 63], [0, 63, 1525, 109], [0, 109, 1525, 153], [0, 153, 1525, 231], [0, 231, 1525, 273], [0, 273, 1525, 315], [0, 315, 1525, 364], [0, 364, 1525, 440], [0, 440, 1525, 525], [0, 525, 1525, 576], [0, 576, 1525, 631]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(img_list)):\n",
    "    img_file = img_list[i]\n",
    "    dets = get_yolo_preds(img_file, docseg_model, conf_thresh)\n",
    "    image = cv2.imread(img_file)\n",
    "    ht, wt, _ = image.shape\n",
    "    processed_dets = post_process_dets(ht, wt, dets, int(ht * 0.05))\n",
    "    final_img = draw_bboxes(img_file, processed_dets)\n",
    "    cv2.imwrite('yolo-rows-' + str(i + 1) + '.jpg', final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59622f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
